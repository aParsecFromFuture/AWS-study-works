{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e1376598",
   "metadata": {},
   "source": [
    "### SageMaker Preprocessor with Scikit-learn Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "a48542a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing sklearn_preprocessor.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile sklearn_preprocessor.py\n",
    "\n",
    "import sys\n",
    "import io\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "import argparse\n",
    "import json\n",
    "import joblib\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OrdinalEncoder, OneHotEncoder\n",
    "\n",
    "from sagemaker_containers.beta.framework import (\n",
    "    content_types, encoders, env, modules, transformer, worker\n",
    ")\n",
    "\n",
    "# Since we got a headerless CSV file we specify the column names here.\n",
    "feature_columns_names = [\n",
    "    \"Loan_ID\",\n",
    "    \"Gender\",\n",
    "    \"Married\",\n",
    "    \"Dependents\",\n",
    "    \"Education\",\n",
    "    \"Self_Employed\",\n",
    "    \"ApplicationIncome\",\n",
    "    \"CoapplicationIncome\",\n",
    "    \"LoanAmount\",\n",
    "    \"Loan_Amount_Term\",\n",
    "    \"Credit_History\",\n",
    "    \"Property_Area\",\n",
    "]\n",
    "\n",
    "label_column = \"Loan_Status\"\n",
    "# Loan_ID\tGender\tMarried\tDependents\tEducation\tSelf_Employed\tApplicantIncome\tCoapplicantIncome\tLoanAmount\tLoan_Amount_Term\tCredit_History\tProperty_Area\n",
    "columns_dtype = {\n",
    "    \"Loan_ID\": \"object\",\n",
    "    \"ApplicationIncome\": \"float64\",\n",
    "    \"CoApplicationIncome\": \"float64\",\n",
    "    \"LoanAmount\": \"float64\",\n",
    "    \"Loan_Amount_Term\": \"float64\",\n",
    "    \"Gender\": \"category\",\n",
    "    \"Married\": \"category\",\n",
    "    \"Dependents\": \"category\",\n",
    "    \"Education\": \"category\",\n",
    "    \"Credit_History\": \"category\",\n",
    "    \"Property_Area\": \"category\",\n",
    "    \"Loan_Status\": \"category\",\n",
    "}\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    parser = argparse.ArgumentParser()\n",
    "    \n",
    "    # Sagemaker specific arguments. Defaults are set in environment variables.\n",
    "    parser.add_argument(\"--output-data-dir\", type=str, default=os.environ[\"SM_OUTPUT_DATA_DIR\"])\n",
    "    parser.add_argument(\"--model-dir\", type=str, default=os.environ[\"SM_MODEL_DIR\"])\n",
    "    parser.add_argument(\"--train\", type=str, default=os.environ[\"SM_CHANNEL_TRAIN\"])\n",
    "    \n",
    "    args = parser.parse_args()\n",
    "    \n",
    "    # Take the set of files and read them all into a single pandas dataframe\n",
    "    input_files = [os.path.join(args.train, file) for file in os.listdir(args.train)]\n",
    "    \n",
    "    if len(input_files) == 0:\n",
    "        raise ValueError((\"There are no files in {}.\\n\" +\n",
    "                          \"This is usually indicates that channel ({}) was incorrectly specified, \\n\" +\n",
    "                          \"the data specification in S3 was incorrectly specified or the role specified\\n\" +\n",
    "                          \"does not have permission to access the data.\").format(args.train, \"train\"))\n",
    "    \n",
    "    raw_data = [pd.read_csv(\n",
    "        file,\n",
    "        header=None,\n",
    "        names=[label_column] + feature_columns_names,\n",
    "        dtype=columns_dtype) for file in input_files\n",
    "    ]\n",
    "    \n",
    "    concat_data = pd.concat(raw_data)\n",
    "    \n",
    "    # Labels should not preprocessed. predict_fn will reinsert the label after featurizing.\n",
    "    concat_data = concat_data.drop(columns=[label_column])\n",
    "    \n",
    "    # Define preprocessing pipeline\n",
    "    preprocessor = make_column_transformer(\n",
    "        (Pipeline([\n",
    "            (\"imputer\", SimpleImputer(strategy=\"mean\")), \n",
    "        ]), [\"ApplicationIncome\", \"CoapplicationIncome\", \"LoanAmount\", \"Loan_Amount_Term\"]),\n",
    "        (Pipeline([\n",
    "            (\"imputer\", SimpleImputer(strategy=\"most_frequent\")), \n",
    "            (\"encoder\", OrdinalEncoder(handle_unknown=\"use_encoded_value\", unknown_value=1024)),\n",
    "        ]), [\"Gender\", \"Married\", \"Dependents\", \"Education\"]),\n",
    "        (Pipeline([\n",
    "            (\"imputer\", SimpleImputer(strategy=\"most_frequent\")), \n",
    "            (\"encoder\", OneHotEncoder(handle_unknown=\"ignore\")),\n",
    "        ]), [\"Property_Area\"]),\n",
    "    )\n",
    "    \n",
    "    preprocessor.fit(concat_data)\n",
    "    \n",
    "    joblib.dump(preprocessor, os.path.join(args.model_dir, \"model.joblib\"))\n",
    "    \n",
    "    print(\"Model Saved!\")\n",
    "    \n",
    "def input_fn(request_body, content_type):\n",
    "    \"\"\"Parse input data payload\n",
    "    \n",
    "    We currently only take csv input. Since we need to process both labelled\n",
    "    and unlabelled data we first determine whether the label column is present\n",
    "    by looking at how many columns were provided.\n",
    "    \"\"\"\n",
    "    if content_type == \"text/csv\":\n",
    "        # Read the raw input data as CSV.\n",
    "        df = pd.read_csv(io.StringIO(request_body), header=None)\n",
    "        \n",
    "        if len(df.columns) == len(feature_columns_names) + 1:\n",
    "            df.columns = [label_column] + feature_columns_names\n",
    "        elif len(df.columns) == len(feature_columns_names):\n",
    "            df.columns = feature_columns_names\n",
    "            \n",
    "        return df\n",
    "    else:\n",
    "        raise ValueError(\"{} not supported by script!\".format(content_type))\n",
    "        \n",
    "\n",
    "def output_fn(prediction, accept):\n",
    "    \"\"\"Format prediction output\n",
    "    \n",
    "    The default content-type between containers for serial inference is JSON.\n",
    "    We also want to set the ContentType or mimetype as the same value as content_type so the\n",
    "    container can read the response payload correctly\n",
    "    \"\"\"\n",
    "    \n",
    "    if accept == \"application/json\":\n",
    "        json_output = {\"instances\": [{\"features\": row} for row in prediction.tolist()]}\n",
    "        return worker.Response(json.dumps(json_output), mimetype=accept)\n",
    "    elif accept == \"text/csv\":\n",
    "        return worker.Response(encoders.encode(prediction, accept), mimetype=accept)\n",
    "    else:\n",
    "        raise ValueError(\"{} accept type is not supported by this script\".format(accept))\n",
    "        \n",
    "\n",
    "def predict_fn(input_data, model):\n",
    "    \"\"\"Preprocess input data\n",
    "\n",
    "    We implement this because the default predict_fn function uses .predict(), but our model is a preprocessor\n",
    "    so we want to use .transform().\n",
    "    \n",
    "    The output is returned in the following order:\n",
    "    \n",
    "        rest of features either one hot encoded or standardized\n",
    "    \"\"\"\n",
    "    features = model.transform(input_data)\n",
    "    \n",
    "    if label_column in input_data:\n",
    "        # Return the label (as the first column) and the set of the features.\n",
    "        input_data[label_column] = input_data[label_column].replace({\"Y\": 1, \"N\": 0})\n",
    "        return np.column_stack([input_data[label_column], features])\n",
    "    else:\n",
    "        # Return only the set of features\n",
    "        return features\n",
    "    \n",
    "    \n",
    "def model_fn(model_dir):\n",
    "    \"\"\"Deserialize fitted model\n",
    "    \"\"\"\n",
    "    preprocessor = joblib.load(os.path.join(model_dir, \"model.joblib\"))\n",
    "    return preprocessor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1a01db4",
   "metadata": {},
   "source": [
    "### SageMaker Estimator with Scikit-learn Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "8ef573a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting sklearn_estimator.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile sklearn_estimator.py\n",
    "\n",
    "import os\n",
    "import io\n",
    "import json\n",
    "import joblib\n",
    "import argparse\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Import SageMaker modules for handling environment and I/O\n",
    "from sagemaker_containers.beta.framework import (\n",
    "    content_types, encoders, env, modules, transformer, worker\n",
    ")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Define command-line arguments\n",
    "    parser = argparse.ArgumentParser()\n",
    "    \n",
    "    # Define default values for training hyperparameters\n",
    "    parser.add_argument('--n-estimators', type=int, default=100) # Number of trees\n",
    "    parser.add_argument('--max-depth', type=int, default=10) # Maximum depth of trees\n",
    "    \n",
    "    # SageMaker environment variables for I/O\n",
    "    parser.add_argument('--output-data-dir', type=str, default=os.environ.get('SM_OUTPUT_DATA_DIR'))\n",
    "    parser.add_argument('--model-dir', type=str, default=os.environ.get('SM_MODEL_DIR'))\n",
    "    parser.add_argument('--train', type=str, default=os.environ.get('SM_CHANNEL_TRAIN'))\n",
    "    \n",
    "    # Parse command-line arguments\n",
    "    args = parser.parse_args()\n",
    "    \n",
    "    # Construct input file paths\n",
    "    input_files = [os.path.join(args.train, file) for file in os.listdir(args.train)]\n",
    "    \n",
    "    # Check if any input files are found\n",
    "    if len(input_files) == 0:\n",
    "        raise ValueError((\"There are no files in {}.\\n\" +\n",
    "                          \"This usually indicates that the channel ({}) was incorrectly specified, \\n\" +\n",
    "                          \"the data specification in S3 was incorrectly specified, or the specified role\\n\" +\n",
    "                          \"does not have permission to access the data.\").format(args.train, \"train\"))\n",
    "    \n",
    "    # Read and concatenate the raw data\n",
    "    raw_data = [pd.read_csv(file, header=None) for file in input_files]\n",
    "    concat_data = pd.concat(raw_data)\n",
    "    \n",
    "    # Split features and labels\n",
    "    X_train = concat_data.iloc[:, 1:]  # Features\n",
    "    y_train = concat_data.iloc[:, 0]   # Labels\n",
    "    \n",
    "    # Initialize and train the RandomForestClassifier\n",
    "    clf = RandomForestClassifier(\n",
    "        n_estimators=args.n_estimators,\n",
    "        max_depth=args.max_depth\n",
    "    )\n",
    "    clf.fit(X_train, y_train)\n",
    "    \n",
    "    # Save the trained model to the model directory\n",
    "    joblib.dump(clf, os.path.join(args.model_dir, \"model.joblib\"))\n",
    "    \n",
    "\n",
    "# SageMaker serving functions\n",
    "def input_fn(request_body, content_type):\n",
    "    \"\"\"Parse input data payload\n",
    "    \n",
    "    Parses the incoming request body and returns the input data for inference.\n",
    "    \"\"\"\n",
    "    if content_type == \"application/json\":\n",
    "        # Parse JSON content\n",
    "        request_body = json.loads(request_body)\n",
    "        features = [instance[\"features\"] for instance in request_body[\"instances\"]]\n",
    "        features = np.asarray(features)\n",
    "        return features\n",
    "    if content_type == \"text/csv\":\n",
    "        # Parse CSV content\n",
    "        df = pd.read_csv(io.StringIO(request_body), header=None)\n",
    "        return df\n",
    "    else:\n",
    "        raise ValueError(\"{} not supported by script\".format(content_type))\n",
    "    \n",
    "    \n",
    "def output_fn(prediction, accept):\n",
    "    \"\"\"Format prediction output\n",
    "    \n",
    "    Formats the prediction output and sets the appropriate content type.\n",
    "    \"\"\"\n",
    "    if accept == \"application/json\":\n",
    "        # Format output as JSON\n",
    "        json_output = {\"instances\": [{\"feature\": row} for row in prediction.tolist()]}\n",
    "        return worker.Response(json.dumps(json_output), mimetype=accept)\n",
    "    if accept == \"text/csv\":\n",
    "        # Encode prediction as CSV\n",
    "        return worker.Response(encoders.encode(prediction, content_type), mimetype=accept)\n",
    "    else:\n",
    "        raise ValueError(\"{} accept type is not supported by script\".format(accept))\n",
    "        \n",
    "        \n",
    "def predict_fn(input_data, model):\n",
    "    \"\"\"Perform prediction\n",
    "    \n",
    "    Uses the provided model to make predictions on input data.\n",
    "    \"\"\"\n",
    "    prediction = model.predict(input_data)\n",
    "    return prediction\n",
    "\n",
    "\n",
    "def model_fn(model_dir):\n",
    "    \"\"\"Perform deserialization\n",
    "    \n",
    "    Loads the trained model from the specified directory.\n",
    "    \"\"\"\n",
    "    model = joblib.load(os.path.join(model_dir, \"model.joblib\"))\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e49bdb79",
   "metadata": {},
   "source": [
    "### SageMaker SKLearn Preprocessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "66cc3078",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating training-job with name: sagemaker-scikit-learn-2024-04-04-13-07-45-721\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-04-04 13:07:46 Starting - Starting the training job...\n",
      "2024-04-04 13:08:04 Starting - Preparing the instances for training...\n",
      "2024-04-04 13:08:47 Downloading - Downloading the training image......\n",
      "2024-04-04 13:09:32 Training - Training image download completed. Training in progress..\u001b[34m2024-04-04 13:09:40,946 sagemaker-containers INFO     Imported framework sagemaker_sklearn_container.training\u001b[0m\n",
      "\u001b[34m2024-04-04 13:09:40,950 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2024-04-04 13:09:40,953 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\u001b[0m\n",
      "\u001b[34m2024-04-04 13:09:40,970 sagemaker_sklearn_container.training INFO     Invoking user training script.\u001b[0m\n",
      "\u001b[34m2024-04-04 13:09:41,201 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2024-04-04 13:09:41,205 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\u001b[0m\n",
      "\u001b[34m2024-04-04 13:09:41,224 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2024-04-04 13:09:41,227 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\u001b[0m\n",
      "\u001b[34m2024-04-04 13:09:41,248 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2024-04-04 13:09:41,251 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\u001b[0m\n",
      "\u001b[34m2024-04-04 13:09:41,267 sagemaker-training-toolkit INFO     Invoking user script\u001b[0m\n",
      "\u001b[34mTraining Env:\u001b[0m\n",
      "\u001b[34m{\n",
      "    \"additional_framework_parameters\": {},\n",
      "    \"channel_input_dirs\": {\n",
      "        \"train\": \"/opt/ml/input/data/train\"\n",
      "    },\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"current_instance_group\": \"homogeneousCluster\",\n",
      "    \"current_instance_group_hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"current_instance_type\": \"ml.m5.xlarge\",\n",
      "    \"distribution_hosts\": [],\n",
      "    \"distribution_instance_groups\": [],\n",
      "    \"framework_module\": \"sagemaker_sklearn_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"hyperparameters\": {},\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {\n",
      "        \"train\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        }\n",
      "    },\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"instance_groups\": [\n",
      "        \"homogeneousCluster\"\n",
      "    ],\n",
      "    \"instance_groups_dict\": {\n",
      "        \"homogeneousCluster\": {\n",
      "            \"instance_group_name\": \"homogeneousCluster\",\n",
      "            \"instance_type\": \"ml.m5.xlarge\",\n",
      "            \"hosts\": [\n",
      "                \"algo-1\"\n",
      "            ]\n",
      "        }\n",
      "    },\n",
      "    \"is_hetero\": false,\n",
      "    \"is_master\": true,\n",
      "    \"is_modelparallel_enabled\": null,\n",
      "    \"is_smddpmprun_installed\": false,\n",
      "    \"is_smddprun_installed\": false,\n",
      "    \"job_name\": \"sagemaker-scikit-learn-2024-04-04-13-07-45-721\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://sagemaker-eu-north-1-339713058917/sagemaker-scikit-learn-2024-04-04-13-07-45-721/source/sourcedir.tar.gz\",\n",
      "    \"module_name\": \"sklearn_preprocessor\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 4,\n",
      "    \"num_gpus\": 0,\n",
      "    \"num_neurons\": 0,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"current_instance_type\": \"ml.m5.xlarge\",\n",
      "        \"current_group_name\": \"homogeneousCluster\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\"\n",
      "        ],\n",
      "        \"instance_groups\": [\n",
      "            {\n",
      "                \"instance_group_name\": \"homogeneousCluster\",\n",
      "                \"instance_type\": \"ml.m5.xlarge\",\n",
      "                \"hosts\": [\n",
      "                    \"algo-1\"\n",
      "                ]\n",
      "            }\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"sklearn_preprocessor.py\"\u001b[0m\n",
      "\u001b[34m}\u001b[0m\n",
      "\u001b[34mEnvironment variables:\u001b[0m\n",
      "\u001b[34mSM_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[34mSM_HPS={}\u001b[0m\n",
      "\u001b[34mSM_USER_ENTRY_POINT=sklearn_preprocessor.py\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_PARAMS={}\u001b[0m\n",
      "\u001b[34mSM_RESOURCE_CONFIG={\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.m5.xlarge\",\"hosts\":[\"algo-1\"],\"instance_groups\":[{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.m5.xlarge\"}],\"network_interface_name\":\"eth0\"}\u001b[0m\n",
      "\u001b[34mSM_INPUT_DATA_CONFIG={\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[34mSM_CHANNELS=[\"train\"]\u001b[0m\n",
      "\u001b[34mSM_CURRENT_HOST=algo-1\u001b[0m\n",
      "\u001b[34mSM_CURRENT_INSTANCE_TYPE=ml.m5.xlarge\u001b[0m\n",
      "\u001b[34mSM_CURRENT_INSTANCE_GROUP=homogeneousCluster\u001b[0m\n",
      "\u001b[34mSM_CURRENT_INSTANCE_GROUP_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_INSTANCE_GROUPS=[\"homogeneousCluster\"]\u001b[0m\n",
      "\u001b[34mSM_INSTANCE_GROUPS_DICT={\"homogeneousCluster\":{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.m5.xlarge\"}}\u001b[0m\n",
      "\u001b[34mSM_DISTRIBUTION_INSTANCE_GROUPS=[]\u001b[0m\n",
      "\u001b[34mSM_IS_HETERO=false\u001b[0m\n",
      "\u001b[34mSM_MODULE_NAME=sklearn_preprocessor\u001b[0m\n",
      "\u001b[34mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_MODULE=sagemaker_sklearn_container.training:main\u001b[0m\n",
      "\u001b[34mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[34mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[34mSM_NUM_CPUS=4\u001b[0m\n",
      "\u001b[34mSM_NUM_GPUS=0\u001b[0m\n",
      "\u001b[34mSM_NUM_NEURONS=0\u001b[0m\n",
      "\u001b[34mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[34mSM_MODULE_DIR=s3://sagemaker-eu-north-1-339713058917/sagemaker-scikit-learn-2024-04-04-13-07-45-721/source/sourcedir.tar.gz\u001b[0m\n",
      "\u001b[34mSM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"train\":\"/opt/ml/input/data/train\"},\"current_host\":\"algo-1\",\"current_instance_group\":\"homogeneousCluster\",\"current_instance_group_hosts\":[\"algo-1\"],\"current_instance_type\":\"ml.m5.xlarge\",\"distribution_hosts\":[],\"distribution_instance_groups\":[],\"framework_module\":\"sagemaker_sklearn_container.training:main\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"instance_groups\":[\"homogeneousCluster\"],\"instance_groups_dict\":{\"homogeneousCluster\":{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.m5.xlarge\"}},\"is_hetero\":false,\"is_master\":true,\"is_modelparallel_enabled\":null,\"is_smddpmprun_installed\":false,\"is_smddprun_installed\":false,\"job_name\":\"sagemaker-scikit-learn-2024-04-04-13-07-45-721\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-eu-north-1-339713058917/sagemaker-scikit-learn-2024-04-04-13-07-45-721/source/sourcedir.tar.gz\",\"module_name\":\"sklearn_preprocessor\",\"network_interface_name\":\"eth0\",\"num_cpus\":4,\"num_gpus\":0,\"num_neurons\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.m5.xlarge\",\"hosts\":[\"algo-1\"],\"instance_groups\":[{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.m5.xlarge\"}],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"sklearn_preprocessor.py\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ARGS=[]\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_TRAIN=/opt/ml/input/data/train\u001b[0m\n",
      "\u001b[34mPYTHONPATH=/opt/ml/code:/miniconda3/bin:/miniconda3/lib/python38.zip:/miniconda3/lib/python3.8:/miniconda3/lib/python3.8/lib-dynload:/miniconda3/lib/python3.8/site-packages\u001b[0m\n",
      "\u001b[34mInvoking script with the following command:\u001b[0m\n",
      "\u001b[34m/miniconda3/bin/python sklearn_preprocessor.py\u001b[0m\n",
      "\u001b[34m2024-04-04 13:09:41,268 sagemaker-training-toolkit INFO     Exceptions not imported for SageMaker Debugger as it is not installed.\u001b[0m\n",
      "\u001b[34m2024-04-04 13:09:41,268 sagemaker-training-toolkit INFO     Exceptions not imported for SageMaker TF as Tensorflow is not installed.\u001b[0m\n",
      "\u001b[34mModel Saved!\u001b[0m\n",
      "\u001b[34m2024-04-04 13:09:42,673 sagemaker-containers INFO     Reporting training SUCCESS\u001b[0m\n",
      "\n",
      "2024-04-04 13:10:01 Uploading - Uploading generated training model\n",
      "2024-04-04 13:10:01 Completed - Training job completed\n",
      "Training seconds: 90\n",
      "Billable seconds: 90\n"
     ]
    }
   ],
   "source": [
    "import sagemaker\n",
    "from sagemaker import get_execution_role\n",
    "from sagemaker.sklearn.estimator import SKLearn\n",
    "\n",
    "sagemaker_session = sagemaker.Session()\n",
    "role = get_execution_role()\n",
    "region = sagemaker_session.boto_region_name\n",
    "train_input = 's3://farukcan-loan-eligibility/train'\n",
    "\n",
    "sklearn_processor = SKLearn(\n",
    "    entry_point=\"sklearn_preprocessor.py\",\n",
    "    framework_version=\"1.2-1\",\n",
    "    role=role,\n",
    "    instance_type=\"ml.m5.xlarge\",\n",
    ")\n",
    "\n",
    "sklearn_processor.fit({\"train\": train_input})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ded959e",
   "metadata": {},
   "source": [
    "### Preprocessing Data with SKLearn Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "107061a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating model with name: sagemaker-scikit-learn-2024-04-04-13-10-28-500\n",
      "INFO:sagemaker:Creating transform job with name: sagemaker-scikit-learn-2024-04-04-13-10-29-250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..............................\u001b[34m2024-04-04 13:15:32,108 INFO - sagemaker-containers - No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2024-04-04 13:15:32,111 INFO - sagemaker-containers - No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2024-04-04 13:15:32,111 INFO - sagemaker-containers - nginx config: \u001b[0m\n",
      "\u001b[34mworker_processes auto;\u001b[0m\n",
      "\u001b[34mdaemon off;\u001b[0m\n",
      "\u001b[34mpid /tmp/nginx.pid;\u001b[0m\n",
      "\u001b[34merror_log  /dev/stderr;\u001b[0m\n",
      "\u001b[34mworker_rlimit_nofile 4096;\u001b[0m\n",
      "\u001b[34mevents {\n",
      "  worker_connections 2048;\u001b[0m\n",
      "\u001b[34m}\u001b[0m\n",
      "\u001b[34mhttp {\n",
      "  include /etc/nginx/mime.types;\n",
      "  default_type application/octet-stream;\n",
      "  access_log /dev/stdout combined;\n",
      "  upstream gunicorn {\n",
      "    server unix:/tmp/gunicorn.sock;\n",
      "  }\n",
      "  server {\n",
      "    listen 8080 deferred;\n",
      "    client_max_body_size 0;\n",
      "    keepalive_timeout 3;\n",
      "    location ~ ^/(ping|invocations|execution-parameters) {\n",
      "      proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;\n",
      "      proxy_set_header Host $http_host;\n",
      "      proxy_redirect off;\n",
      "      proxy_read_timeout 60s;\n",
      "      proxy_pass http://gunicorn;\n",
      "    }\n",
      "    location / {\n",
      "      return 404 \"{}\";\n",
      "    }\n",
      "  }\u001b[0m\n",
      "\u001b[34m}\u001b[0m\n",
      "\u001b[34m2024-04-04 13:15:32,340 INFO - sagemaker-containers - Module sklearn_preprocessor does not provide a setup.py. \u001b[0m\n",
      "\u001b[34mGenerating setup.py\u001b[0m\n",
      "\u001b[34m2024-04-04 13:15:32,340 INFO - sagemaker-containers - Generating setup.cfg\u001b[0m\n",
      "\u001b[34m2024-04-04 13:15:32,341 INFO - sagemaker-containers - Generating MANIFEST.in\u001b[0m\n",
      "\u001b[34m2024-04-04 13:15:32,341 INFO - sagemaker-containers - Installing module with the following command:\u001b[0m\n",
      "\u001b[34m/miniconda3/bin/python -m pip install . \u001b[0m\n",
      "\u001b[34mProcessing /opt/ml/code\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\u001b[0m\n",
      "\u001b[34mBuilding wheels for collected packages: sklearn-preprocessor\n",
      "  Building wheel for sklearn-preprocessor (setup.py): started\n",
      "  Building wheel for sklearn-preprocessor (setup.py): finished with status 'done'\n",
      "  Created wheel for sklearn-preprocessor: filename=sklearn_preprocessor-1.0.0-py2.py3-none-any.whl size=7251 sha256=9c0363017e9e46da5bb3fd48654232d47c235d39aa757d7ca0ea93caa3c0bb0f\n",
      "  Stored in directory: /home/model-server/tmp/pip-ephem-wheel-cache-vg2xc0r3/wheels/f3/75/57/158162e9eab7af12b5c338c279b3a81f103b89d74eeb911c00\u001b[0m\n",
      "\u001b[34mSuccessfully built sklearn-preprocessor\u001b[0m\n",
      "\u001b[34mInstalling collected packages: sklearn-preprocessor\u001b[0m\n",
      "\u001b[34mSuccessfully installed sklearn-preprocessor-1.0.0\u001b[0m\n",
      "\u001b[34m[2024-04-04 13:15:34 +0000] [33] [INFO] Starting gunicorn 20.0.4\u001b[0m\n",
      "\u001b[34m[2024-04-04 13:15:34 +0000] [33] [INFO] Listening at: unix:/tmp/gunicorn.sock (33)\u001b[0m\n",
      "\u001b[34m[2024-04-04 13:15:34 +0000] [33] [INFO] Using worker: gevent\u001b[0m\n",
      "\u001b[34m[2024-04-04 13:15:34 +0000] [35] [INFO] Booting worker with pid: 35\u001b[0m\n",
      "\u001b[34m[2024-04-04 13:15:34 +0000] [36] [INFO] Booting worker with pid: 36\u001b[0m\n",
      "\u001b[34m[2024-04-04 13:15:34 +0000] [37] [INFO] Booting worker with pid: 37\u001b[0m\n",
      "\u001b[34m[2024-04-04 13:15:35 +0000] [38] [INFO] Booting worker with pid: 38\u001b[0m\n",
      "\u001b[34m2024-04-04 13:15:37,498 INFO - sagemaker-containers - No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[35m2024-04-04 13:15:37,498 INFO - sagemaker-containers - No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [04/Apr/2024:13:15:38 +0000] \"GET /ping HTTP/1.1\" 200 0 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [04/Apr/2024:13:15:38 +0000] \"GET /execution-parameters HTTP/1.1\" 404 232 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [04/Apr/2024:13:15:38 +0000] \"POST /invocations HTTP/1.1\" 200 34983 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[35m169.254.255.130 - - [04/Apr/2024:13:15:38 +0000] \"GET /ping HTTP/1.1\" 200 0 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[35m169.254.255.130 - - [04/Apr/2024:13:15:38 +0000] \"GET /execution-parameters HTTP/1.1\" 404 232 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[35m169.254.255.130 - - [04/Apr/2024:13:15:38 +0000] \"POST /invocations HTTP/1.1\" 200 34983 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[32m2024-04-04T13:15:38.086:[sagemaker logs]: MaxConcurrentTransforms=1, MaxPayloadInMB=6, BatchStrategy=MULTI_RECORD\u001b[0m\n",
      "\n",
      "Waiting for transform job: sagemaker-scikit-learn-2024-04-04-13-10-29-250\n",
      "\u001b[34m2024-04-04 13:15:32,108 INFO - sagemaker-containers - No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2024-04-04 13:15:32,111 INFO - sagemaker-containers - No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2024-04-04 13:15:32,111 INFO - sagemaker-containers - nginx config: \u001b[0m\n",
      "\u001b[34mworker_processes auto;\u001b[0m\n",
      "\u001b[34mdaemon off;\u001b[0m\n",
      "\u001b[34mpid /tmp/nginx.pid;\u001b[0m\n",
      "\u001b[34merror_log  /dev/stderr;\u001b[0m\n",
      "\u001b[34mworker_rlimit_nofile 4096;\u001b[0m\n",
      "\u001b[34mevents {\n",
      "  worker_connections 2048;\u001b[0m\n",
      "\u001b[34m}\u001b[0m\n",
      "\u001b[34mhttp {\n",
      "  include /etc/nginx/mime.types;\n",
      "  default_type application/octet-stream;\n",
      "  access_log /dev/stdout combined;\n",
      "  upstream gunicorn {\n",
      "    server unix:/tmp/gunicorn.sock;\n",
      "  }\n",
      "  server {\n",
      "    listen 8080 deferred;\n",
      "    client_max_body_size 0;\n",
      "    keepalive_timeout 3;\n",
      "    location ~ ^/(ping|invocations|execution-parameters) {\n",
      "      proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;\n",
      "      proxy_set_header Host $http_host;\n",
      "      proxy_redirect off;\n",
      "      proxy_read_timeout 60s;\n",
      "      proxy_pass http://gunicorn;\n",
      "    }\n",
      "    location / {\n",
      "      return 404 \"{}\";\n",
      "    }\n",
      "  }\u001b[0m\n",
      "\u001b[34m}\u001b[0m\n",
      "\u001b[34m2024-04-04 13:15:32,340 INFO - sagemaker-containers - Module sklearn_preprocessor does not provide a setup.py. \u001b[0m\n",
      "\u001b[34mGenerating setup.py\u001b[0m\n",
      "\u001b[34m2024-04-04 13:15:32,340 INFO - sagemaker-containers - Generating setup.cfg\u001b[0m\n",
      "\u001b[35m2024-04-04 13:15:32,108 INFO - sagemaker-containers - No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[35m2024-04-04 13:15:32,111 INFO - sagemaker-containers - No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[35m2024-04-04 13:15:32,111 INFO - sagemaker-containers - nginx config: \u001b[0m\n",
      "\u001b[35mworker_processes auto;\u001b[0m\n",
      "\u001b[35mdaemon off;\u001b[0m\n",
      "\u001b[35mpid /tmp/nginx.pid;\u001b[0m\n",
      "\u001b[35merror_log  /dev/stderr;\u001b[0m\n",
      "\u001b[35mworker_rlimit_nofile 4096;\u001b[0m\n",
      "\u001b[35mevents {\n",
      "  worker_connections 2048;\u001b[0m\n",
      "\u001b[35m}\u001b[0m\n",
      "\u001b[35mhttp {\n",
      "  include /etc/nginx/mime.types;\n",
      "  default_type application/octet-stream;\n",
      "  access_log /dev/stdout combined;\n",
      "  upstream gunicorn {\n",
      "    server unix:/tmp/gunicorn.sock;\n",
      "  }\n",
      "  server {\n",
      "    listen 8080 deferred;\n",
      "    client_max_body_size 0;\n",
      "    keepalive_timeout 3;\n",
      "    location ~ ^/(ping|invocations|execution-parameters) {\n",
      "      proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;\n",
      "      proxy_set_header Host $http_host;\n",
      "      proxy_redirect off;\n",
      "      proxy_read_timeout 60s;\n",
      "      proxy_pass http://gunicorn;\n",
      "    }\n",
      "    location / {\n",
      "      return 404 \"{}\";\n",
      "    }\n",
      "  }\u001b[0m\n",
      "\u001b[35m}\u001b[0m\n",
      "\u001b[35m2024-04-04 13:15:32,340 INFO - sagemaker-containers - Module sklearn_preprocessor does not provide a setup.py. \u001b[0m\n",
      "\u001b[35mGenerating setup.py\u001b[0m\n",
      "\u001b[35m2024-04-04 13:15:32,340 INFO - sagemaker-containers - Generating setup.cfg\u001b[0m\n",
      "\u001b[34m2024-04-04 13:15:32,341 INFO - sagemaker-containers - Generating MANIFEST.in\u001b[0m\n",
      "\u001b[34m2024-04-04 13:15:32,341 INFO - sagemaker-containers - Installing module with the following command:\u001b[0m\n",
      "\u001b[34m/miniconda3/bin/python -m pip install . \u001b[0m\n",
      "\u001b[35m2024-04-04 13:15:32,341 INFO - sagemaker-containers - Generating MANIFEST.in\u001b[0m\n",
      "\u001b[35m2024-04-04 13:15:32,341 INFO - sagemaker-containers - Installing module with the following command:\u001b[0m\n",
      "\u001b[35m/miniconda3/bin/python -m pip install . \u001b[0m\n",
      "\u001b[34mProcessing /opt/ml/code\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\u001b[0m\n",
      "\u001b[34mBuilding wheels for collected packages: sklearn-preprocessor\n",
      "  Building wheel for sklearn-preprocessor (setup.py): started\n",
      "  Building wheel for sklearn-preprocessor (setup.py): finished with status 'done'\n",
      "  Created wheel for sklearn-preprocessor: filename=sklearn_preprocessor-1.0.0-py2.py3-none-any.whl size=7251 sha256=9c0363017e9e46da5bb3fd48654232d47c235d39aa757d7ca0ea93caa3c0bb0f\n",
      "  Stored in directory: /home/model-server/tmp/pip-ephem-wheel-cache-vg2xc0r3/wheels/f3/75/57/158162e9eab7af12b5c338c279b3a81f103b89d74eeb911c00\u001b[0m\n",
      "\u001b[34mSuccessfully built sklearn-preprocessor\u001b[0m\n",
      "\u001b[35mProcessing /opt/ml/code\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\u001b[0m\n",
      "\u001b[35mBuilding wheels for collected packages: sklearn-preprocessor\n",
      "  Building wheel for sklearn-preprocessor (setup.py): started\n",
      "  Building wheel for sklearn-preprocessor (setup.py): finished with status 'done'\n",
      "  Created wheel for sklearn-preprocessor: filename=sklearn_preprocessor-1.0.0-py2.py3-none-any.whl size=7251 sha256=9c0363017e9e46da5bb3fd48654232d47c235d39aa757d7ca0ea93caa3c0bb0f\n",
      "  Stored in directory: /home/model-server/tmp/pip-ephem-wheel-cache-vg2xc0r3/wheels/f3/75/57/158162e9eab7af12b5c338c279b3a81f103b89d74eeb911c00\u001b[0m\n",
      "\u001b[35mSuccessfully built sklearn-preprocessor\u001b[0m\n",
      "\u001b[34mInstalling collected packages: sklearn-preprocessor\u001b[0m\n",
      "\u001b[34mSuccessfully installed sklearn-preprocessor-1.0.0\u001b[0m\n",
      "\u001b[35mInstalling collected packages: sklearn-preprocessor\u001b[0m\n",
      "\u001b[35mSuccessfully installed sklearn-preprocessor-1.0.0\u001b[0m\n",
      "\u001b[34m[2024-04-04 13:15:34 +0000] [33] [INFO] Starting gunicorn 20.0.4\u001b[0m\n",
      "\u001b[34m[2024-04-04 13:15:34 +0000] [33] [INFO] Listening at: unix:/tmp/gunicorn.sock (33)\u001b[0m\n",
      "\u001b[34m[2024-04-04 13:15:34 +0000] [33] [INFO] Using worker: gevent\u001b[0m\n",
      "\u001b[34m[2024-04-04 13:15:34 +0000] [35] [INFO] Booting worker with pid: 35\u001b[0m\n",
      "\u001b[34m[2024-04-04 13:15:34 +0000] [36] [INFO] Booting worker with pid: 36\u001b[0m\n",
      "\u001b[34m[2024-04-04 13:15:34 +0000] [37] [INFO] Booting worker with pid: 37\u001b[0m\n",
      "\u001b[34m[2024-04-04 13:15:35 +0000] [38] [INFO] Booting worker with pid: 38\u001b[0m\n",
      "\u001b[35m[2024-04-04 13:15:34 +0000] [33] [INFO] Starting gunicorn 20.0.4\u001b[0m\n",
      "\u001b[35m[2024-04-04 13:15:34 +0000] [33] [INFO] Listening at: unix:/tmp/gunicorn.sock (33)\u001b[0m\n",
      "\u001b[35m[2024-04-04 13:15:34 +0000] [33] [INFO] Using worker: gevent\u001b[0m\n",
      "\u001b[35m[2024-04-04 13:15:34 +0000] [35] [INFO] Booting worker with pid: 35\u001b[0m\n",
      "\u001b[35m[2024-04-04 13:15:34 +0000] [36] [INFO] Booting worker with pid: 36\u001b[0m\n",
      "\u001b[35m[2024-04-04 13:15:34 +0000] [37] [INFO] Booting worker with pid: 37\u001b[0m\n",
      "\u001b[35m[2024-04-04 13:15:35 +0000] [38] [INFO] Booting worker with pid: 38\u001b[0m\n",
      "\u001b[34m2024-04-04 13:15:37,498 INFO - sagemaker-containers - No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[35m2024-04-04 13:15:37,498 INFO - sagemaker-containers - No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [04/Apr/2024:13:15:38 +0000] \"GET /ping HTTP/1.1\" 200 0 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [04/Apr/2024:13:15:38 +0000] \"GET /execution-parameters HTTP/1.1\" 404 232 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [04/Apr/2024:13:15:38 +0000] \"POST /invocations HTTP/1.1\" 200 34983 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[35m169.254.255.130 - - [04/Apr/2024:13:15:38 +0000] \"GET /ping HTTP/1.1\" 200 0 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[35m169.254.255.130 - - [04/Apr/2024:13:15:38 +0000] \"GET /execution-parameters HTTP/1.1\" 404 232 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[35m169.254.255.130 - - [04/Apr/2024:13:15:38 +0000] \"POST /invocations HTTP/1.1\" 200 34983 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[32m2024-04-04T13:15:38.086:[sagemaker logs]: MaxConcurrentTransforms=1, MaxPayloadInMB=6, BatchStrategy=MULTI_RECORD\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "sklearn_transformer = sklearn_processor.transformer(\n",
    "    instance_count=1, instance_type=\"ml.m5.xlarge\", assemble_with=\"Line\", accept=\"text/csv\",\n",
    ")\n",
    "\n",
    "sklearn_transformer.transform(train_input, content_type=\"text/csv\")\n",
    "print(\"Waiting for transform job: \" + sklearn_transformer.latest_transform_job.job_name)\n",
    "sklearn_transformer.wait()\n",
    "\n",
    "preprocessed_train = sklearn_transformer.output_path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c670fa0",
   "metadata": {},
   "source": [
    "### Training SKLearn Estimator with Preprocessed Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "c0ed758c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating training-job with name: sagemaker-scikit-learn-2024-04-04-13-20-19-880\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-04-04 13:20:20 Starting - Starting the training job...\n",
      "2024-04-04 13:20:37 Starting - Preparing the instances for training...\n",
      "2024-04-04 13:21:15 Downloading - Downloading the training image......\n",
      "2024-04-04 13:22:18 Training - Training image download completed. Training in progress.\n",
      "2024-04-04 13:22:18 Uploading - Uploading generated training model\u001b[34m2024-04-04 13:22:09,594 sagemaker-containers INFO     Imported framework sagemaker_sklearn_container.training\u001b[0m\n",
      "\u001b[34m2024-04-04 13:22:09,597 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2024-04-04 13:22:09,599 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\u001b[0m\n",
      "\u001b[34m2024-04-04 13:22:09,613 sagemaker_sklearn_container.training INFO     Invoking user training script.\u001b[0m\n",
      "\u001b[34m2024-04-04 13:22:09,830 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2024-04-04 13:22:09,833 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\u001b[0m\n",
      "\u001b[34m2024-04-04 13:22:09,850 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2024-04-04 13:22:09,853 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\u001b[0m\n",
      "\u001b[34m2024-04-04 13:22:09,871 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2024-04-04 13:22:09,874 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\u001b[0m\n",
      "\u001b[34m2024-04-04 13:22:09,888 sagemaker-training-toolkit INFO     Invoking user script\u001b[0m\n",
      "\u001b[34mTraining Env:\u001b[0m\n",
      "\u001b[34m{\n",
      "    \"additional_framework_parameters\": {},\n",
      "    \"channel_input_dirs\": {\n",
      "        \"train\": \"/opt/ml/input/data/train\"\n",
      "    },\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"current_instance_group\": \"homogeneousCluster\",\n",
      "    \"current_instance_group_hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"current_instance_type\": \"ml.m5.xlarge\",\n",
      "    \"distribution_hosts\": [],\n",
      "    \"distribution_instance_groups\": [],\n",
      "    \"framework_module\": \"sagemaker_sklearn_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"hyperparameters\": {\n",
      "        \"max-depth\": 8,\n",
      "        \"n-estimators\": 100\n",
      "    },\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {\n",
      "        \"train\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        }\n",
      "    },\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"instance_groups\": [\n",
      "        \"homogeneousCluster\"\n",
      "    ],\n",
      "    \"instance_groups_dict\": {\n",
      "        \"homogeneousCluster\": {\n",
      "            \"instance_group_name\": \"homogeneousCluster\",\n",
      "            \"instance_type\": \"ml.m5.xlarge\",\n",
      "            \"hosts\": [\n",
      "                \"algo-1\"\n",
      "            ]\n",
      "        }\n",
      "    },\n",
      "    \"is_hetero\": false,\n",
      "    \"is_master\": true,\n",
      "    \"is_modelparallel_enabled\": null,\n",
      "    \"is_smddpmprun_installed\": false,\n",
      "    \"is_smddprun_installed\": false,\n",
      "    \"job_name\": \"sagemaker-scikit-learn-2024-04-04-13-20-19-880\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://sagemaker-eu-north-1-339713058917/sagemaker-scikit-learn-2024-04-04-13-20-19-880/source/sourcedir.tar.gz\",\n",
      "    \"module_name\": \"sklearn_estimator\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 4,\n",
      "    \"num_gpus\": 0,\n",
      "    \"num_neurons\": 0,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"current_instance_type\": \"ml.m5.xlarge\",\n",
      "        \"current_group_name\": \"homogeneousCluster\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\"\n",
      "        ],\n",
      "        \"instance_groups\": [\n",
      "            {\n",
      "                \"instance_group_name\": \"homogeneousCluster\",\n",
      "                \"instance_type\": \"ml.m5.xlarge\",\n",
      "                \"hosts\": [\n",
      "                    \"algo-1\"\n",
      "                ]\n",
      "            }\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"sklearn_estimator.py\"\u001b[0m\n",
      "\u001b[34m}\u001b[0m\n",
      "\u001b[34mEnvironment variables:\u001b[0m\n",
      "\u001b[34mSM_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[34mSM_HPS={\"max-depth\":8,\"n-estimators\":100}\u001b[0m\n",
      "\u001b[34mSM_USER_ENTRY_POINT=sklearn_estimator.py\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_PARAMS={}\u001b[0m\n",
      "\u001b[34mSM_RESOURCE_CONFIG={\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.m5.xlarge\",\"hosts\":[\"algo-1\"],\"instance_groups\":[{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.m5.xlarge\"}],\"network_interface_name\":\"eth0\"}\u001b[0m\n",
      "\u001b[34mSM_INPUT_DATA_CONFIG={\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[34mSM_CHANNELS=[\"train\"]\u001b[0m\n",
      "\u001b[34mSM_CURRENT_HOST=algo-1\u001b[0m\n",
      "\u001b[34mSM_CURRENT_INSTANCE_TYPE=ml.m5.xlarge\u001b[0m\n",
      "\u001b[34mSM_CURRENT_INSTANCE_GROUP=homogeneousCluster\u001b[0m\n",
      "\u001b[34mSM_CURRENT_INSTANCE_GROUP_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_INSTANCE_GROUPS=[\"homogeneousCluster\"]\u001b[0m\n",
      "\u001b[34mSM_INSTANCE_GROUPS_DICT={\"homogeneousCluster\":{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.m5.xlarge\"}}\u001b[0m\n",
      "\u001b[34mSM_DISTRIBUTION_INSTANCE_GROUPS=[]\u001b[0m\n",
      "\u001b[34mSM_IS_HETERO=false\u001b[0m\n",
      "\u001b[34mSM_MODULE_NAME=sklearn_estimator\u001b[0m\n",
      "\u001b[34mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_MODULE=sagemaker_sklearn_container.training:main\u001b[0m\n",
      "\u001b[34mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[34mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[34mSM_NUM_CPUS=4\u001b[0m\n",
      "\u001b[34mSM_NUM_GPUS=0\u001b[0m\n",
      "\u001b[34mSM_NUM_NEURONS=0\u001b[0m\n",
      "\u001b[34mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[34mSM_MODULE_DIR=s3://sagemaker-eu-north-1-339713058917/sagemaker-scikit-learn-2024-04-04-13-20-19-880/source/sourcedir.tar.gz\u001b[0m\n",
      "\u001b[34mSM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"train\":\"/opt/ml/input/data/train\"},\"current_host\":\"algo-1\",\"current_instance_group\":\"homogeneousCluster\",\"current_instance_group_hosts\":[\"algo-1\"],\"current_instance_type\":\"ml.m5.xlarge\",\"distribution_hosts\":[],\"distribution_instance_groups\":[],\"framework_module\":\"sagemaker_sklearn_container.training:main\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{\"max-depth\":8,\"n-estimators\":100},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"instance_groups\":[\"homogeneousCluster\"],\"instance_groups_dict\":{\"homogeneousCluster\":{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.m5.xlarge\"}},\"is_hetero\":false,\"is_master\":true,\"is_modelparallel_enabled\":null,\"is_smddpmprun_installed\":false,\"is_smddprun_installed\":false,\"job_name\":\"sagemaker-scikit-learn-2024-04-04-13-20-19-880\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-eu-north-1-339713058917/sagemaker-scikit-learn-2024-04-04-13-20-19-880/source/sourcedir.tar.gz\",\"module_name\":\"sklearn_estimator\",\"network_interface_name\":\"eth0\",\"num_cpus\":4,\"num_gpus\":0,\"num_neurons\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.m5.xlarge\",\"hosts\":[\"algo-1\"],\"instance_groups\":[{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.m5.xlarge\"}],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"sklearn_estimator.py\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ARGS=[\"--max-depth\",\"8\",\"--n-estimators\",\"100\"]\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_TRAIN=/opt/ml/input/data/train\u001b[0m\n",
      "\u001b[34mSM_HP_MAX-DEPTH=8\u001b[0m\n",
      "\u001b[34mSM_HP_N-ESTIMATORS=100\u001b[0m\n",
      "\u001b[34mPYTHONPATH=/opt/ml/code:/miniconda3/bin:/miniconda3/lib/python38.zip:/miniconda3/lib/python3.8:/miniconda3/lib/python3.8/lib-dynload:/miniconda3/lib/python3.8/site-packages\u001b[0m\n",
      "\u001b[34mInvoking script with the following command:\u001b[0m\n",
      "\u001b[34m/miniconda3/bin/python sklearn_estimator.py --max-depth 8 --n-estimators 100\u001b[0m\n",
      "\u001b[34m2024-04-04 13:22:09,889 sagemaker-training-toolkit INFO     Exceptions not imported for SageMaker Debugger as it is not installed.\u001b[0m\n",
      "\u001b[34m2024-04-04 13:22:09,889 sagemaker-training-toolkit INFO     Exceptions not imported for SageMaker TF as Tensorflow is not installed.\u001b[0m\n",
      "\u001b[34m2024-04-04 13:22:11,297 sagemaker-containers INFO     Reporting training SUCCESS\u001b[0m\n",
      "\n",
      "2024-04-04 13:22:29 Completed - Training job completed\n",
      "Training seconds: 89\n",
      "Billable seconds: 89\n"
     ]
    }
   ],
   "source": [
    "from sagemaker import get_execution_role\n",
    "from sagemaker.sklearn.estimator import SKLearn\n",
    "\n",
    "# Get the execution role\n",
    "role = get_execution_role()\n",
    "\n",
    "# Configure the SKLearn estimator\n",
    "sklearn_estimator = SKLearn(\n",
    "    entry_point='sklearn_estimator.py',  # Name of the entry point script\n",
    "    framework_version='1.0-1',  # SKLearn framework version\n",
    "    role=role,\n",
    "    instance_type='ml.m5.xlarge',  # Instance type for training\n",
    "    hyperparameters={'n-estimators': 100, 'max-depth': 8},  # Hyperparameters for training\n",
    ")\n",
    "\n",
    "sklearn_estimator.fit({\"train\": preprocessed_train})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5be3df1e",
   "metadata": {},
   "source": [
    "### Deploying Inference Pipeline with SKLearn Processor and Estimator Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "3be66f79",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating model with name: inference-pipeline-2024-04-04-13-23-03-692\n",
      "INFO:sagemaker:Creating endpoint-config with name inference-pipeline-ep-2024-04-04-13-23-03-692\n",
      "INFO:sagemaker:Creating endpoint with name inference-pipeline-ep-2024-04-04-13-23-03-692\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------!"
     ]
    }
   ],
   "source": [
    "from sagemaker.pipeline import PipelineModel\n",
    "from sagemaker.utils import name_from_base\n",
    "\n",
    "sklearn_processor_model = sklearn_processor.create_model()\n",
    "sklearn_estimator_model = sklearn_estimator.create_model()\n",
    "\n",
    "model_name = name_from_base(\"inference-pipeline\")\n",
    "endpoint_name = name_from_base(\"inference-pipeline-ep\")\n",
    "\n",
    "sm_model = PipelineModel(\n",
    "    name=model_name, role=role, models=[sklearn_processor_model, sklearn_estimator_model]\n",
    ")\n",
    "\n",
    "sm_model.deploy(\n",
    "    initial_instance_count=1, \n",
    "    instance_type=\"ml.m5.xlarge\", \n",
    "    endpoint_name=endpoint_name,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b5710d3",
   "metadata": {},
   "source": [
    "### Making Predictions Using Deployed Inference Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "e9696f07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'{\"instances\": [{\"feature\": 1.0}]}'\n"
     ]
    }
   ],
   "source": [
    "from sagemaker.predictor import Predictor\n",
    "from sagemaker.serializers import CSVSerializer\n",
    "\n",
    "predictor = Predictor(\n",
    "    endpoint_name=endpoint_name, serializer=CSVSerializer(), sagemaker_session=sagemaker_session,\n",
    ")\n",
    "\n",
    "payload = \"LP001003, Male, Yes, 1, Graduate, No, 4583, 1508.0, 128.0, 360.0, 1.0, Rural\"\n",
    "\n",
    "prediction = predictor.predict(payload)\n",
    "print(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52bc3a63",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
